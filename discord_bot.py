#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Discord Bot Ä‘á»ƒ táº£i sÃ¡ch tá»« Z-Library vÃ  upload lÃªn Google Drive
Workflow: Discord Input â†’ Z-Library Download â†’ Rclone Upload â†’ Share Link â†’ Cleanup

CÃ¡ch dÃ¹ng:
1. Invite bot vÃ o server Discord
2. DÃ¹ng command: !download <z-library-url>
3. Bot sáº½ táº£i sÃ¡ch vÃ  tráº£ vá» Google Drive link
"""

import asyncio
import os
import re
import subprocess
import sys
from pathlib import Path
from typing import Optional

import discord
from discord.ext import commands
import yaml

# Import cÃ¡c module tá»« project
from config.config_manager import ConfigManager
from services.zlibrary_service import ZLibraryService
from utils.logger import setup_logger, get_logger
import logging

# ===== Cáº¤U HÃŒNH =====
# Load config first to get Discord token
try:
    config_manager = ConfigManager("config.yaml")
    discord_config = config_manager.config.get('discord', {})
    DISCORD_TOKEN = discord_config.get('token', 'YOUR_DISCORD_BOT_TOKEN')
    TEMP_DIR = discord_config.get('temp_dir', 'data/temp')
except Exception as e:
    print(f"âš ï¸ Error loading config: {e}")
    DISCORD_TOKEN = "YOUR_DISCORD_BOT_TOKEN"
    TEMP_DIR = "data/temp"

RCLONE_REMOTE = "discord"  # â† Sá»¬A: TÃªn remote trong rclone config
RCLONE_FOLDER = "ZLibrary-Books"  # Folder trÃªn Google Drive
DOWNLOAD_DIR = "data/downloads/discord"  # ThÆ° má»¥c download táº¡m
AUTO_DELETE_AFTER_UPLOAD = True  # Tá»± Ä‘á»™ng xÃ³a file sau khi upload

# ===== SETUP =====
setup_logger(logging.INFO, "logs/discord_bot.log")
logger = get_logger("discord_bot")

# Discord Bot intents
intents = discord.Intents.default()
intents.message_content = True  # Váº«n giá»¯ cho backward compatibility

# Sá»­ dá»¥ng commands.Bot Ä‘á»ƒ há»— trá»£ cáº£ slash commands vÃ  prefix commands
bot = commands.Bot(
    command_prefix='!',  # Prefix commands (legacy)
    intents=intents,
    help_command=None  # Disable default help Ä‘á»ƒ dÃ¹ng custom
)


class BookDownloader:
    """
    Class xá»­ lÃ½ download sÃ¡ch tá»« Z-Library
    
    TÆ°Æ¡ng tá»± logic trong test_download_single_book.py
    Há»— trá»£:
    - Direct download link (/dl/)
    - Book page link (/book/)
    - Tá»± Ä‘á»™ng parse domain (.ec, .se, .is, ...)
    """
    
    def __init__(self):
        self.config_manager = ConfigManager("config.yaml")
        zlib_config = self.config_manager.get_zlibrary_config()
        
        self.zlibrary_service = ZLibraryService(
            email=zlib_config.get('username'),
            password=zlib_config.get('password'),
            proxy_list=zlib_config.get('proxy_list'),
            format_priority=zlib_config.get('format_priority', ['pdf', 'epub', 'mobi']),
            download_dir=DOWNLOAD_DIR
        )
        
        os.makedirs(DOWNLOAD_DIR, exist_ok=True)
        logger.info("BookDownloader initialized")
    
    def reload_credentials(self, username: str, password: str):
        """
        Reload Z-Library credentials without restarting bot
        
        Args:
            username: Z-Library email
            password: Z-Library password
        """
        try:
            # Update config file
            import yaml
            config_path = "config.yaml"
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = yaml.safe_load(f)
            
            # Update zlibrary section
            if 'zlibrary' not in config_data:
                config_data['zlibrary'] = {}
            
            config_data['zlibrary']['username'] = username
            config_data['zlibrary']['password'] = password
            
            # Write back to file
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config_data, f, default_flow_style=False, allow_unicode=True)
            
            # Reload ConfigManager
            self.config_manager = ConfigManager(config_path)
            zlib_config = self.config_manager.get_zlibrary_config()
            
            # Recreate ZLibraryService with new credentials
            self.zlibrary_service = ZLibraryService(
                email=username,
                password=password,
                proxy_list=zlib_config.get('proxy_list'),
                format_priority=zlib_config.get('format_priority', ['pdf', 'epub', 'mobi']),
                download_dir=DOWNLOAD_DIR
            )
            
            logger.info(f"Credentials reloaded for user: {username}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to reload credentials: {e}")
            return False
    
    def extract_book_info_from_url(self, url: str) -> Optional[dict]:
        """
        TrÃ­ch xuáº¥t thÃ´ng tin tá»« URL Z-Library
        
        Há»— trá»£ cÃ¡c domain: .ec, .se, .is, .sk, ...
        Pattern: https://z-library.{domain}/book/{id}/{hash}
                 https://z-library.{domain}/dl/{id}/{hash}
        
        Supported URL formats:
        âœ… /book/1269938/e536b6
        âœ… /book/1269938/e536b6/filename.html
        âœ… /book/1269938/e536b6?ts=1651
        âœ… /book/1269938/e536b6?dsource=recommend
        âœ… /book/1269938/e536b6/title.html?utm_source=google&utm_campaign=xyz
        âœ… /book/1269938/e536b6#section
        âœ… /dl/1269938/b88232 (direct download)
        """
        # Remove ALL query params (?xxx) and fragments (#xxx)
        # This handles: ?ts=, ?dsource=, ?utm_source=, ?ref=, etc.
        clean_url = url.split('?')[0].split('#')[0]
        
        # Pattern 1: /book/{id}/{hash}[/optional-filename.ext] (book page)
        # Regex: /book/(\d+)/([a-z0-9]+)(?:/[^/]+)?
        #   - (\d+): book ID (digits)
        #   - ([a-z0-9]+): hash (alphanumeric, case-insensitive)
        #   - (?:/[^/]+)?: optional non-capturing group for filename
        match = re.search(r'/book/(\d+)/([a-z0-9]+)(?:/[^/]+)?', clean_url, re.IGNORECASE)
        if match:
            return {
                'id': match.group(1),
                'hash': match.group(2),
                'url': url,
                'type': 'book_page',
                'domain': self._extract_domain(url)
            }
        
        # Pattern 2: /dl/{id}/{hash} (direct download)
        # Note: Some hashes may contain letters beyond a-f (not strictly hex)
        match = re.search(r'/dl/(\d+)/([a-z0-9]+)', clean_url)
        if match:
            return {
                'id': match.group(1),
                'hash': match.group(2),
                'url': url,
                'type': 'direct_download',
                'domain': self._extract_domain(url)
            }
        
        return None
    
    def _extract_domain(self, url: str) -> str:
        """TrÃ­ch xuáº¥t domain tá»« URL"""
        import re
        match = re.search(r'https?://([^/]+)', url)
        if match:
            return match.group(1)
        return 'z-library.ec'  # Default
    
    async def _get_download_hash_from_page(self, book_page_url: str) -> Optional[str]:
        """
        Parse book page HTML Ä‘á»ƒ láº¥y download hash tháº­t tá»« download button
        
        HTML structure:
        <a class="btn btn-default addDownloadedBook" href="/dl/1269938/f07321">
            <span>pdf</span>, 19.30 MB
        </a>
        
        Returns:
            str: Download hash (e.g., 'f07321') hoáº·c None náº¿u khÃ´ng tÃ¬m tháº¥y
        """
        try:
            import requests
            from bs4 import BeautifulSoup
            
            logger.info(f"Fetching book page: {book_page_url}")
            
            # Add proper headers to mimic browser
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }
            
            response = requests.get(book_page_url, headers=headers, timeout=10)
            response.raise_for_status()
            
            # Debug: Save HTML to file for inspection
            debug_html_path = "data/temp/debug_page.html"
            os.makedirs(os.path.dirname(debug_html_path), exist_ok=True)
            with open(debug_html_path, 'w', encoding='utf-8') as f:
                f.write(response.text)
            logger.info(f"Saved HTML to {debug_html_path} for debugging")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Method 1: Find by class "addDownloadedBook" (most reliable)
            # Priority: Look for primary download button (usually PDF, first format)
            download_links = soup.find_all('a', class_='addDownloadedBook')
            
            download_link = None
            if download_links:
                logger.info(f"Found {len(download_links)} download button(s)")
                # Debug: Log all found links
                for i, link in enumerate(download_links):
                    href = link.get('href')
                    format_span = link.find('span', class_='book-property__extension')
                    fmt = format_span.text.strip() if format_span else 'unknown'
                    logger.info(f"  Button {i+1}: {href} (format: {fmt})")
                
                # Take the first one (primary format)
                download_link = download_links[0]
                logger.info(f"Using first button")
            
            if not download_link:
                # Method 2: Find any <a> with href matching /dl/{id}/{hash}
                download_link = soup.find('a', href=re.compile(r'/dl/\d+/[a-z0-9]+', re.IGNORECASE))
                logger.info("Using fallback method to find download link")
            
            if download_link:
                href = download_link.get('href')
                # Try to get format from button text
                format_span = download_link.find('span', class_='book-property__extension')
                file_format = format_span.text.strip() if format_span else 'unknown'
                logger.info(f"Found download link: {href} (format: {file_format})")
                
                # Extract hash from /dl/{id}/{hash}
                match = re.search(r'/dl/\d+/([a-z0-9]+)', href, re.IGNORECASE)
                if match:
                    download_hash = match.group(1)
                    logger.info(f"Found download hash: {download_hash}")
                    return download_hash
            
            logger.warning("Could not find download link in book page")
            return None
            
        except Exception as e:
            logger.error(f"Error parsing book page: {e}")
            return None
    
    async def download_book(self, url: str) -> Optional[dict]:
        """
        Download sÃ¡ch tá»« Z-Library
        
        Returns:
            dict: {
                'success': bool,
                'file_path': str,
                'file_name': str,
                'file_size': int,
                'title': str,
                'error': str (if failed)
            }
        """
        try:
            logger.info(f"Báº¯t Ä‘áº§u download tá»« URL: {url}")
            
            # Parse URL
            book_info = self.extract_book_info_from_url(url)
            if not book_info:
                return {
                    'success': False,
                    'error': 'URL khÃ´ng há»£p lá»‡. Vui lÃ²ng cung cáº¥p URL tá»« Z-Library'
                }
            
            # Get book ID (works for both /book/ and /dl/ URLs)
            book_id = book_info['id']
            
            # IMPORTANT: Hash in URL expires! We must search to get fresh download_url
            # Strategy: Extract title from URL filename -> search by title -> match by ID
            logger.info(f"Book ID: {book_id}")
            
            try:
                import requests
                from bs4 import BeautifulSoup
                
                # Step 1: Fetch book page to extract ISBN
                # ISBN is unique identifier - perfect for exact search!
                book_page_url = url.split('?')[0].split('#')[0]
                if '/dl/' in book_page_url:
                    # Convert /dl/ to /book/ to access book page
                    book_page_url = book_page_url.replace('/dl/', '/book/')
                    # Remove hash part: /book/ID/hash â†’ /book/ID
                    parts = book_page_url.split('/')
                    if len(parts) >= 6:  # https://domain/book/ID/hash
                        book_page_url = '/'.join(parts[:5])  # Keep only up to ID
                
                logger.info(f"Fetching book page to extract ISBN: {book_page_url}")
                
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                
                try:
                    response = requests.get(book_page_url, headers=headers, timeout=10)
                    response.raise_for_status()
                except Exception as e:
                    logger.error(f"Failed to fetch book page: {e}")
                    return {
                        'success': False,
                        'error': f'âŒ KhÃ´ng thá»ƒ truy cáº­p trang sÃ¡ch: {str(e)}'
                    }
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Step 2: Extract ISBN from meta description or page content
                # Example: <meta name="description" content="...ISBN: 9780194420884...">
                isbn = None
                
                # Method 1: Check meta description
                meta_desc = soup.find('meta', attrs={'name': 'description'})
                if meta_desc and meta_desc.get('content'):
                    desc_content = meta_desc.get('content')
                    # Look for ISBN pattern: ISBN: XXXXXXXXXX or ISBN-10/13
                    isbn_match = re.search(r'ISBN[:\s-]*(\d{10,13})', desc_content, re.IGNORECASE)
                    if isbn_match:
                        isbn = isbn_match.group(1)
                        logger.info(f"Found ISBN in meta description: {isbn}")
                
                # Method 2: Look in page content for ISBN
                if not isbn:
                    # Find all text containing "ISBN"
                    isbn_elements = soup.find_all(string=re.compile(r'ISBN', re.IGNORECASE))
                    for elem in isbn_elements:
                        isbn_match = re.search(r'ISBN[:\s-]*(\d{10,13})', elem, re.IGNORECASE)
                        if isbn_match:
                            isbn = isbn_match.group(1)
                            logger.info(f"Found ISBN in page content: {isbn}")
                            break
                
                # Method 3: Look for data attributes or structured data
                if not isbn:
                    # Sometimes ISBN is in structured data (JSON-LD)
                    script_tags = soup.find_all('script', type='application/ld+json')
                    for script in script_tags:
                        try:
                            import json
                            data = json.loads(script.string)
                            if 'isbn' in data:
                                isbn = str(data['isbn'])
                                logger.info(f"Found ISBN in structured data: {isbn}")
                                break
                        except:
                            pass
                
                # Step 3: Search by ISBN (most accurate!) or fallback to get_by_id
                if not isbn:
                    logger.warning("No ISBN found in page, trying get_by_id API...")
                    
                    # Try using zlibrary's get_by_id (may fail on some domains)
                    lib = self.zlibrary_service.search_service.lib
                    
                    async def get_book_by_id():
                        try:
                            # Try to get book directly by ID
                            book = await lib.get_by_id(str(book_id))
                            return book
                        except Exception as e:
                            logger.error(f"get_by_id failed: {e}")
                            return None
                    
                    book_details = asyncio.run(get_book_by_id())
                    
                    if not book_details:
                        return {
                            'success': False,
                            'error': 'âŒ URL khÃ´ng cÃ³ tÃªn sÃ¡ch vÃ  khÃ´ng thá»ƒ tÃ¬m theo ID\n\n' +
                                    'ğŸ’¡ Vui lÃ²ng dÃ¹ng URL cÃ³ tÃªn sÃ¡ch, vÃ­ dá»¥:\n' +
                                    'âœ… https://z-library.xx/book/123/abc/book-title.html\n' +
                                    'âŒ https://z-library.xx/book/123/abc'
                        }
                    
                    # Got book details directly, extract info
                    download_url = book_details.get('download_url')
                    if not download_url:
                        return {
                            'success': False,
                            'error': 'âŒ SÃ¡ch khÃ´ng cÃ³ link download'
                        }
                    
                    title = book_details.get('name', f'Book_{book_id}')
                    authors = book_details.get('authors', 'Unknown')
                    extension = book_details.get('extension', 'pdf')
                    
                    logger.info(f"Got book via get_by_id: {title}")
                    
                    # Skip search, go directly to download
                    book_data = {
                        'zlibrary_id': book_id,
                        'title': title,
                        'authors': authors,
                        'download_url': download_url,
                        'extension': extension,
                        'url': url
                    }
                    
                    logger.info(f"Downloading book ID: {book_id} (using zlibrary service authenticated session)")
                    file_path = self.zlibrary_service.download_book(book_data, DOWNLOAD_DIR)
                    
                    if not file_path or not os.path.exists(file_path):
                        return {
                            'success': False,
                            'error': 'Download tháº¥t báº¡i. File khÃ´ng tá»“n táº¡i sau khi download.'
                        }
                    
                    # Continue to upload...
                    file_size = os.path.getsize(file_path)
                    file_name = os.path.basename(file_path)
                    
                    logger.info(f"Download thÃ nh cÃ´ng: {file_name} ({file_size} bytes)")
                    
                    # Upload to Google Drive
                    logger.info(f"Uploading {file_name} lÃªn {RCLONE_REMOTE}:{RCLONE_FOLDER}/{file_name}")
                    uploader = RcloneUploader(RCLONE_REMOTE, RCLONE_FOLDER)
                    
                    upload_result = uploader.upload_file(file_path)
                    if not upload_result['success']:
                        return {
                            'success': False,
                            'error': f"Upload tháº¥t báº¡i: {upload_result.get('error', 'Unknown error')}"
                        }
                    
                    logger.info(f"Upload thÃ nh cÃ´ng: {upload_result['remote_path']}")
                    
                    # Get public link
                    link_result = uploader.get_public_link(file_name)
                    public_link = link_result.get('link', 'KhÃ´ng thá»ƒ táº¡o public link')
                    
                    logger.info(f"Public link created: {public_link}")
                    
                    # Cleanup
                    if AUTO_DELETE_AFTER_UPLOAD:
                        try:
                            os.remove(file_path)
                            logger.info(f"ÄÃ£ xÃ³a file local: {file_path}")
                        except Exception as e:
                            logger.warning(f"KhÃ´ng thá»ƒ xÃ³a file: {e}")
                    
                    logger.info(f"HoÃ n thÃ nh download qua get_by_id: {file_name}")
                    
                    return {
                        'success': True,
                        'file_name': file_name,
                        'file_size': file_size,
                        'public_link': public_link,
                        'remote_path': upload_result['remote_path']
                    }
                
                # Step 4: Search by ISBN (exact match!)
                lib = self.zlibrary_service.search_service.lib
                logger.info(f"Searching Z-Library by ISBN: {isbn}")
                
                async def search_by_isbn():
                    # Try multiple search strategies
                    # Strategy 1: Search with just ISBN number
                    paginator = await lib.search(q=isbn, count=5)
                    await paginator.next()
                    if paginator.result:
                        return paginator.result
                    
                    # Strategy 2: Try with isbn: prefix
                    paginator = await lib.search(q=f"isbn:{isbn}", count=5)
                    await paginator.next()
                    return paginator.result
                
                results = asyncio.run(search_by_isbn())
                
                if not results:
                    logger.error(f"No results found for ISBN: {isbn}")
                    # Fallback to get_by_id if ISBN search fails
                    logger.warning("ISBN search failed, trying get_by_id...")
                    
                    async def get_book_by_id():
                        try:
                            book = await lib.get_by_id(str(book_id))
                            return book
                        except Exception as e:
                            logger.error(f"get_by_id failed: {e}")
                            return None
                    
                    book_details = asyncio.run(get_book_by_id())
                    
                    if not book_details:
                        return {
                            'success': False,
                            'error': f'âŒ KhÃ´ng tÃ¬m tháº¥y sÃ¡ch (ISBN: {isbn}, ID: {book_id})'
                        }
                    
                    # Got book directly, skip to download
                    download_url = book_details.get('download_url')
                    if not download_url:
                        return {
                            'success': False,
                            'error': 'âŒ SÃ¡ch khÃ´ng cÃ³ link download'
                        }
                    
                    title = book_details.get('name', f'Book_{book_id}')
                    authors = book_details.get('authors', 'Unknown')
                    extension = book_details.get('extension', 'pdf')
                    
                    logger.info(f"Got book via get_by_id: {title}")
                else:
                    # ISBN search succeeded - continue normal flow
                    # ISBN search should return exact match, use first result
                    book_result = results[0]
                    logger.info(f"Found book by ISBN: {book_result.get('name', 'Unknown')}")
                    
                    # Step 5: Fetch full details with download_url
                    logger.info(f"Fetching book details...")
                    book_details = asyncio.run(book_result.fetch())
                    
                    download_url = book_details.get('download_url')
                    if not download_url:
                        logger.error(f"Book details missing download_url")
                        return {
                            'success': False,
                            'error': 'âŒ SÃ¡ch khÃ´ng cÃ³ link download kháº£ dá»¥ng'
                        }
                    
                    title = book_details.get('name', f'Book_{book_id}')
                    authors = book_details.get('authors', 'Unknown')
                    extension = book_details.get('extension', 'pdf')
                
                logger.info(f"Got fresh download_url: {download_url}")
                
                logger.info(f"Got fresh download_url: {download_url}")
                
            except Exception as e:
                logger.error(f"Error getting fresh download URL: {e}")
                import traceback
                traceback.print_exc()
                return {
                    'success': False,
                    'error': f'âŒ Lá»—i: {str(e)}'
                }
            
            # Chuáº©n bá»‹ book_info cho service
            book_data = {
                'zlibrary_id': book_id,
                'title': title,
                'authors': authors,
                'download_url': download_url,
                'extension': extension,
                'url': url
            }
            logger.info(f"Downloading book ID: {book_info['id']} (using zlibrary service authenticated session)")
            file_path = self.zlibrary_service.download_book(book_data, DOWNLOAD_DIR)
            
            if not file_path or not os.path.exists(file_path):
                return {
                    'success': False,
                    'error': 'Download tháº¥t báº¡i. File khÃ´ng tá»“n táº¡i sau khi download.'
                }
            
            # Láº¥y thÃ´ng tin file
            file_size = os.path.getsize(file_path)
            file_name = os.path.basename(file_path)
            
            logger.info(f"Download thÃ nh cÃ´ng: {file_name} ({file_size} bytes)")
            
            return {
                'success': True,
                'file_path': file_path,
                'file_name': file_name,
                'file_size': file_size,
                'title': title
            }
            
        except Exception as e:
            logger.error(f"Lá»—i khi download: {str(e)}")
            return {
                'success': False,
                'error': f'Lá»—i: {str(e)}'
            }


class RcloneUploader:
    """Class xá»­ lÃ½ upload lÃªn Google Drive báº±ng Rclone"""
    
    def __init__(self, remote: str, folder: str):
        self.remote = remote
        self.folder = folder
        logger.info(f"RcloneUploader initialized: {remote}:{folder}")
    
    def check_rclone_installed(self) -> bool:
        """Kiá»ƒm tra xem rclone Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t chÆ°a"""
        try:
            result = subprocess.run(['rclone', 'version'], 
                                   capture_output=True, 
                                   text=True, 
                                   timeout=5)
            return result.returncode == 0
        except Exception as e:
            logger.error(f"Rclone khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t: {e}")
            return False
    
    async def upload_file(self, file_path: str) -> Optional[dict]:
        """
        Upload file lÃªn Google Drive
        
        Returns:
            dict: {
                'success': bool,
                'remote_path': str,
                'share_link': str (if available),
                'error': str (if failed)
            }
        """
        try:
            if not self.check_rclone_installed():
                return {
                    'success': False,
                    'error': 'Rclone chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t trÃªn VPS'
                }
            
            file_name = os.path.basename(file_path)
            remote_path = f"{self.remote}:{self.folder}/{file_name}"
            
            logger.info(f"Uploading {file_name} lÃªn {remote_path}")
            
            # Upload vá»›i progress
            cmd = [
                'rclone', 'copy',
                file_path,
                f"{self.remote}:{self.folder}",
                '--progress',
                '--stats', '1s'
            ]
            
            # Cháº¡y rclone
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode != 0:
                error_msg = stderr.decode('utf-8')
                logger.error(f"Upload tháº¥t báº¡i: {error_msg}")
                return {
                    'success': False,
                    'error': f'Rclone error: {error_msg}'
                }
            
            logger.info(f"Upload thÃ nh cÃ´ng: {remote_path}")
            
            # Táº¡o public link (náº¿u cÃ³ thá»ƒ)
            share_link = await self.create_public_link(file_name)
            
            return {
                'success': True,
                'remote_path': remote_path,
                'file_name': file_name,
                'share_link': share_link
            }
            
        except Exception as e:
            logger.error(f"Lá»—i khi upload: {str(e)}")
            return {
                'success': False,
                'error': f'Lá»—i: {str(e)}'
            }
    
    async def create_public_link(self, file_name: str) -> Optional[str]:
        """
        Táº¡o public link cho file (náº¿u Google Drive há»— trá»£)
        
        Note: Cáº§n cáº¥u hÃ¬nh rclone vá»›i Google Drive API
        """
        try:
            # Láº¥y link tá»« rclone link
            cmd = [
                'rclone', 'link',
                f"{self.remote}:{self.folder}/{file_name}"
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                link = stdout.decode('utf-8').strip()
                logger.info(f"Public link created: {link}")
                return link
            else:
                logger.warning("KhÃ´ng thá»ƒ táº¡o public link, cÃ³ thá»ƒ cáº§n cáº¥u hÃ¬nh thÃªm")
                return None
                
        except Exception as e:
            logger.warning(f"KhÃ´ng thá»ƒ táº¡o public link: {e}")
            return None


# ===== DISCORD BOT COMMANDS =====

downloader = BookDownloader()
uploader = RcloneUploader(RCLONE_REMOTE, RCLONE_FOLDER)


@bot.event
async def on_ready():
    logger.info(f'Bot Ä‘Ã£ Ä‘Äƒng nháº­p: {bot.user.name}')
    print(f'âœ… Bot Ä‘Ã£ sáºµn sÃ ng: {bot.user.name}')
    print(f'ğŸ“š Slash commands: /download, /quota, /ping, /help')
    print(f'ğŸ“š Prefix commands: !download, !quota, !ping, !help_bot')
    
    # Sync slash commands vá»›i Discord
    try:
        synced = await bot.tree.sync()
        logger.info(f"ÄÃ£ sync {len(synced)} slash command(s)")
        print(f"âœ… ÄÃ£ sync {len(synced)} slash command(s)")
    except Exception as e:
        logger.error(f"Lá»—i khi sync commands: {e}")
        print(f"âš ï¸  Lá»—i sync commands: {e}")


# ===== HELPER FUNCTION =====

async def process_download_request(interaction_or_ctx, url: str, is_slash: bool = False):
    """
    Helper function xá»­ lÃ½ download request
    DÃ¹ng chung cho cáº£ slash command vÃ  prefix command
    
    Args:
        interaction_or_ctx: discord.Interaction (slash) hoáº·c commands.Context (prefix)
        url: Z-Library URL
        is_slash: True náº¿u lÃ  slash command, False náº¿u lÃ  prefix command
    """
    # Get author info and initialize status_msg
    status_msg = None
    if is_slash:
        author = interaction_or_ctx.user
        # Defer Ä‘á»ƒ cÃ³ thá»i gian xá»­ lÃ½ (15 phÃºt thay vÃ¬ 3 giÃ¢y)
        await interaction_or_ctx.response.defer()
    else:
        author = interaction_or_ctx.author
        status_msg = await interaction_or_ctx.send(f"â³ Äang xá»­ lÃ½ request cá»§a {author.mention}...")
    
    try:
        # BÆ°á»›c 1: Download
        if is_slash:
            await interaction_or_ctx.followup.send(f"ğŸ“¥ **[1/4]** Äang download sÃ¡ch tá»« Z-Library...\nâ³ Request tá»« {author.mention}")
        else:
            await status_msg.edit(content="ğŸ“¥ **[1/4]** Äang download sÃ¡ch tá»« Z-Library...")
        
        logger.info(f"User {author} yÃªu cáº§u download: {url}")
        
        download_result = await downloader.download_book(url)
        
        if not download_result['success']:
            error_msg = f"âŒ **Download tháº¥t báº¡i:**\n```{download_result['error']}```"
            if is_slash:
                await interaction_or_ctx.followup.send(error_msg)
            else:
                await status_msg.edit(content=error_msg)
            return
        
        file_path = download_result['file_path']
        file_name = download_result['file_name']
        file_size_mb = download_result['file_size'] / (1024 * 1024)
        
        # BÆ°á»›c 2: Upload lÃªn Google Drive
        upload_msg = f"â˜ï¸ **[2/4]** Äang upload `{file_name}` ({file_size_mb:.2f} MB) lÃªn Google Drive..."
        if is_slash:
            await interaction_or_ctx.followup.send(upload_msg)
        else:
            await status_msg.edit(content=upload_msg)
        
        upload_result = await uploader.upload_file(file_path)
        
        if not upload_result['success']:
            error_msg = f"âŒ **Upload tháº¥t báº¡i:**\n```{upload_result['error']}```"
            if is_slash:
                await interaction_or_ctx.followup.send(error_msg)
            else:
                await status_msg.edit(content=error_msg)
            return
        
        # BÆ°á»›c 3: Táº¡o message káº¿t quáº£
        if is_slash:
            await interaction_or_ctx.followup.send("ğŸ“‹ **[3/4]** Äang táº¡o thÃ´ng tin chia sáº»...")
        else:
            await status_msg.edit(content="ğŸ“‹ **[3/4]** Äang táº¡o thÃ´ng tin chia sáº»...")
        
        embed = discord.Embed(
            title="âœ… Download & Upload ThÃ nh CÃ´ng!",
            color=discord.Color.green(),
            description=f"SÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c táº£i vÃ  upload lÃªn Google Drive"
        )
        
        embed.add_field(name="ğŸ“– File Name", value=f"`{file_name}`", inline=False)
        embed.add_field(name="ğŸ“Š File Size", value=f"{file_size_mb:.2f} MB", inline=True)
        embed.add_field(name="â˜ï¸ Remote Path", value=f"`{upload_result['remote_path']}`", inline=False)
        
        if upload_result.get('share_link'):
            embed.add_field(name="ğŸ”— Public Link", value=upload_result['share_link'], inline=False)
        else:
            embed.add_field(
                name="ğŸ“ Access", 
                value=f"File Ä‘Ã£ Ä‘Æ°á»£c upload vÃ o folder `{RCLONE_FOLDER}` trÃªn Google Drive\n"
                      f"DÃ¹ng lá»‡nh `rclone link {RCLONE_REMOTE}:{RCLONE_FOLDER}/{file_name}` Ä‘á»ƒ láº¥y link",
                inline=False
            )
        
        embed.set_footer(text=f"Requested by {author.name}", icon_url=author.avatar.url if author.avatar else None)
        
        if is_slash:
            await interaction_or_ctx.followup.send(embed=embed)
        else:
            await status_msg.edit(content=None, embed=embed)
        
        # BÆ°á»›c 4: Cleanup (xÃ³a file local náº¿u Ä‘Æ°á»£c báº­t)
        if AUTO_DELETE_AFTER_UPLOAD:
            await asyncio.sleep(2)
            try:
                os.remove(file_path)
                logger.info(f"ÄÃ£ xÃ³a file local: {file_path}")
                cleanup_msg = f"ğŸ—‘ï¸ **[4/4]** ÄÃ£ xÃ³a file táº¡m trÃªn VPS"
                if is_slash:
                    await interaction_or_ctx.followup.send(cleanup_msg)
                else:
                    await interaction_or_ctx.send(cleanup_msg)
            except Exception as e:
                logger.warning(f"KhÃ´ng thá»ƒ xÃ³a file: {e}")
        
        logger.info(f"HoÃ n thÃ nh request cho user {author}: {file_name}")
        
    except Exception as e:
        logger.error(f"Lá»—i khi xá»­ lÃ½ command: {e}")
        error_msg = f"âŒ **Lá»—i khÃ´ng mong muá»‘n:**\n```{str(e)}```"
        if is_slash:
            await interaction_or_ctx.followup.send(error_msg)
        else:
            await status_msg.edit(content=error_msg)


# ===== SLASH COMMANDS =====

@bot.tree.command(name="download", description="ğŸ“¥ Download sÃ¡ch tá»« Z-Library vÃ  upload lÃªn Google Drive")
async def slash_download(interaction: discord.Interaction, url: str):
    """
    Slash command: /download <url>
    
    Parameters:
        url: URL cá»§a sÃ¡ch trÃªn Z-Library (.ec, .se, .is, .sk)
    """
    await process_download_request(interaction, url, is_slash=True)


@bot.tree.command(name="quota", description="ğŸ“Š Kiá»ƒm tra quota Z-Library cÃ²n láº¡i")
async def slash_quota(interaction: discord.Interaction):
    """Slash command: /quota"""
    await interaction.response.defer()
    
    try:
        limits = downloader.zlibrary_service.get_download_limits()
        
        embed = discord.Embed(
            title="ğŸ“Š Z-Library Download Quota",
            color=discord.Color.blue()
        )
        
        embed.add_field(name="Daily Limit", value=limits.get('daily_amount', 'N/A'), inline=True)
        embed.add_field(name="Remaining", value=limits.get('daily_remaining', 'N/A'), inline=True)
        embed.add_field(name="Next Reset", value=limits.get('daily_reset', 'N/A'), inline=False)
        
        await interaction.followup.send(embed=embed)
        
    except Exception as e:
        await interaction.followup.send(f"âŒ KhÃ´ng thá»ƒ láº¥y thÃ´ng tin quota: {str(e)}")


@bot.tree.command(name="set_credentials", description="ğŸ”‘ Thay Ä‘á»•i Z-Library credentials (khi háº¿t quota)")
async def slash_set_credentials(interaction: discord.Interaction, email: str, password: str):
    """
    Slash command: /set_credentials <email> <password>
    
    Thay Ä‘á»•i Z-Library account credentials
    Há»¯u Ã­ch khi account hiá»‡n táº¡i háº¿t quota
    
    Parameters:
        email: Z-Library email/username
        password: Z-Library password
    """
    # Check if user has permission (optional - cÃ³ thá»ƒ thÃªm role check)
    # if not interaction.user.guild_permissions.administrator:
    #     await interaction.response.send_message("âŒ Chá»‰ admin má»›i cÃ³ thá»ƒ thay Ä‘á»•i credentials!", ephemeral=True)
    #     return
    
    await interaction.response.defer(ephemeral=True)  # Response riÃªng tÆ° (chá»‰ user tháº¥y)
    
    try:
        # Reload credentials
        success = downloader.reload_credentials(email, password)
        
        if success:
            # Get new quota info
            try:
                limits = downloader.zlibrary_service.get_download_limits()
                quota_info = (
                    f"\n\nğŸ“Š **New Account Quota:**\n"
                    f"â€¢ Daily Limit: {limits.get('daily_amount', 'N/A')}\n"
                    f"â€¢ Remaining: {limits.get('daily_remaining', 'N/A')}\n"
                    f"â€¢ Next Reset: {limits.get('daily_reset', 'N/A')}"
                )
            except:
                quota_info = ""
            
            await interaction.followup.send(
                f"âœ… **Credentials Updated Successfully!**\n"
                f"ğŸ“§ New account: `{email}`\n"
                f"ğŸ” Password: `{'*' * len(password)}`"
                f"{quota_info}",
                ephemeral=True
            )
            
            logger.info(f"Credentials changed by {interaction.user.name} to {email}")
            
        else:
            await interaction.followup.send(
                f"âŒ **Failed to update credentials!**\n"
                f"Check logs for details.",
                ephemeral=True
            )
    
    except Exception as e:
        logger.error(f"Error changing credentials: {e}")
        await interaction.followup.send(
            f"âŒ **Error:**\n```{str(e)}```",
            ephemeral=True
        )


@bot.tree.command(name="version", description="ğŸ“¦ Kiá»ƒm tra version code bot")
async def slash_version(interaction: discord.Interaction):
    """Slash command: /version - Check bot version"""
    try:
        import subprocess
        # Get git commit hash
        commit = subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD']).decode('ascii').strip()
        # Get git commit date
        commit_date = subprocess.check_output(['git', 'log', '-1', '--format=%cd', '--date=short']).decode('ascii').strip()
        
        embed = discord.Embed(
            title="ğŸ“¦ Bot Version Info",
            color=discord.Color.blue()
        )
        embed.add_field(name="Git Commit", value=f"`{commit}`", inline=True)
        embed.add_field(name="Commit Date", value=commit_date, inline=True)
        embed.add_field(name="Status", value="âœ… Running with HTML parsing fix", inline=False)
        
        await interaction.response.send_message(embed=embed)
    except Exception as e:
        await interaction.response.send_message(f"âš ï¸ Cannot get version: {str(e)}")


@bot.tree.command(name="ping", description="ğŸ“ Kiá»ƒm tra bot cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng")
async def slash_ping(interaction: discord.Interaction):
    """Slash command: /ping"""
    latency_ms = round(bot.latency * 1000)
    await interaction.response.send_message(f'ğŸ“ Pong! Latency: {latency_ms}ms')


@bot.tree.command(name="help", description="ğŸ“š Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n sá»­ dá»¥ng bot")
async def slash_help(interaction: discord.Interaction):
    """Slash command: /help"""
    embed = discord.Embed(
        title="ğŸ“š Z-Library Discord Bot - HÆ°á»›ng Dáº«n",
        description="Bot tá»± Ä‘á»™ng download sÃ¡ch tá»« Z-Library vÃ  upload lÃªn Google Drive",
        color=discord.Color.purple()
    )
    
    embed.add_field(
        name="âš¡ Slash Commands (Modern)",
        value=(
            "`/download <url>` - Download vÃ  upload sÃ¡ch\n"
            "`/quota` - Kiá»ƒm tra quota cÃ²n láº¡i\n"
            "`/set_credentials <email> <password>` - Äá»•i Z-Library account\n"
            "`/ping` - Test bot\n"
            "`/help` - Xem hÆ°á»›ng dáº«n nÃ y"
        ),
        inline=False
    )
    
    embed.add_field(
        name="ğŸ“ Prefix Commands (Legacy)",
        value=(
            "`!download <url>` - Download vÃ  upload sÃ¡ch\n"
            "`!quota` - Kiá»ƒm tra quota\n"
            "`!ping` - Test bot\n"
            "`!help_bot` - Xem hÆ°á»›ng dáº«n"
        ),
        inline=False
    )
    
    embed.add_field(
        name="ğŸ”— Supported URL Types",
        value=(
            "Bot tá»± Ä‘á»™ng tÃ¬m vÃ  download vá»›i URL má»›i nháº¥t!\n\n"
            "âœ… **Book page:** `https://z-library.xx/book/123456/abc123`\n"
            "âœ… **Direct link:** `https://z-library.xx/dl/123456/abc123`\n\n"
            "ğŸ’¡ **Tip:** Copy báº¥t ká»³ link nÃ o tá»« Z-Library Ä‘á»u Ä‘Æ°á»£c!"
        ),
        inline=False
    )
    
    embed.set_footer(text="Powered by Z-Library + Rclone")
    
    await interaction.response.send_message(embed=embed)


# ===== PREFIX COMMANDS (Backward Compatible) =====

@bot.command(name='download', help='Download sÃ¡ch tá»« Z-Library vÃ  upload lÃªn Google Drive')
async def download_command(ctx, url: str = None):
    """
    Prefix command: !download <z-library-url>
    """
    if not url:
        await ctx.send(
            "âŒ Vui lÃ²ng cung cáº¥p URL Z-Library!\n"
            "**VÃ­ dá»¥:**\n"
            "â€¢ `!download https://z-library.ec/book/12345/abcdef`\n"
            "â€¢ `!download https://z-library.ec/dl/12345/abcdef` (direct link)\n\n"
            "ğŸ’¡ **Tip:** DÃ¹ng slash command `/download` cho tráº£i nghiá»‡m tá»‘t hÆ¡n!"
        )
        return
    
    await process_download_request(ctx, url, is_slash=False)


@bot.command(name='ping', help='Kiá»ƒm tra bot cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng')
async def ping_command(ctx):
    """Prefix command: !ping"""
    latency_ms = round(bot.latency * 1000)
    await ctx.send(
        f'ğŸ“ Pong! Latency: {latency_ms}ms\n'
        f'ğŸ’¡ **Tip:** DÃ¹ng `/ping` cho tráº£i nghiá»‡m tá»‘t hÆ¡n!'
    )


@bot.command(name='quota', help='Kiá»ƒm tra quota Z-Library cÃ²n láº¡i')
async def quota_command(ctx):
    """Prefix command: !quota"""
    try:
        limits = downloader.zlibrary_service.get_download_limits()
        
        embed = discord.Embed(
            title="ğŸ“Š Z-Library Download Quota",
            color=discord.Color.blue()
        )
        
        embed.add_field(name="Daily Limit", value=limits.get('daily_amount', 'N/A'), inline=True)
        embed.add_field(name="Remaining", value=limits.get('daily_remaining', 'N/A'), inline=True)
        embed.add_field(name="Next Reset", value=limits.get('daily_reset', 'N/A'), inline=False)
        
        embed.set_footer(text="ğŸ’¡ Tip: DÃ¹ng /quota cho tráº£i nghiá»‡m tá»‘t hÆ¡n!")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ KhÃ´ng thá»ƒ láº¥y thÃ´ng tin quota: {str(e)}")


@bot.command(name='help_bot', help='Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n sá»­ dá»¥ng')
async def help_bot_command(ctx):
    """Prefix command: !help_bot (redirects to /help)"""
    await ctx.send(
        "ï¿½ **Bot Ä‘Ã£ chuyá»ƒn sang dÃ¹ng Slash Commands!**\n"
        "GÃµ `/help` Ä‘á»ƒ xem hÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§\n\n"
        "**Quick commands:**\n"
        "â€¢ `/download <url>` - Download sÃ¡ch\n"
        "â€¢ `/quota` - Check quota\n"
        "â€¢ `/ping` - Test bot\n"
        "â€¢ `/help` - Xem hÆ°á»›ng dáº«n chi tiáº¿t"
    )


# ===== MAIN =====

def main():
    """Khá»Ÿi Ä‘á»™ng Discord Bot"""
    
    if DISCORD_TOKEN == "YOUR_DISCORD_BOT_TOKEN":
        print("âŒ Lá»—i: ChÆ°a cáº¥u hÃ¬nh DISCORD_TOKEN")
        print("Vui lÃ²ng sá»­a DISCORD_TOKEN trong file discord_bot.py")
        return
    
    print("=" * 80)
    print("ğŸ¤– DISCORD BOT - Z-LIBRARY DOWNLOADER")
    print("=" * 80)
    print()
    print("âœ… Äang khá»Ÿi Ä‘á»™ng bot...")
    print(f"ğŸ“ Download directory: {DOWNLOAD_DIR}")
    print(f"â˜ï¸  Rclone remote: {RCLONE_REMOTE}:{RCLONE_FOLDER}")
    print(f"ğŸ—‘ï¸  Auto delete: {AUTO_DELETE_AFTER_UPLOAD}")
    print()
    
    try:
        bot.run(DISCORD_TOKEN)
    except Exception as e:
        logger.error(f"Lá»—i khi cháº¡y bot: {e}")
        print(f"âŒ Lá»—i: {e}")


if __name__ == "__main__":
    main()
