#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Discord Bot ƒë·ªÉ t·∫£i s√°ch t·ª´ Z-Library v√† upload l√™n Google Drive
Workflow: Discord Input ‚Üí Z-Library Download ‚Üí Rclone Upload ‚Üí Share Link ‚Üí Cleanup

C√°ch d√πng:
1. Invite bot v√†o server Discord
2. D√πng command: !download <z-library-url>
3. Bot s·∫Ω t·∫£i s√°ch v√† tr·∫£ v·ªÅ Google Drive link
"""

import asyncio
import os
import re
import subprocess
import sys
from pathlib import Path
from typing import Optional

import discord
from discord.ext import commands
import yaml

# Import c√°c module t·ª´ project
from config.config_manager import ConfigManager
from services.zlibrary_service import ZLibraryService
from utils.logger import setup_logger, get_logger
import logging

# ===== C·∫§U H√åNH =====
# Load config first to get Discord token
try:
    config_manager = ConfigManager("config.yaml")
    discord_config = config_manager.config.get('discord', {})
    DISCORD_TOKEN = discord_config.get('token', 'YOUR_DISCORD_BOT_TOKEN')
    TEMP_DIR = discord_config.get('temp_dir', 'data/temp')
except Exception as e:
    print(f"‚ö†Ô∏è Error loading config: {e}")
    DISCORD_TOKEN = "YOUR_DISCORD_BOT_TOKEN"
    TEMP_DIR = "data/temp"

RCLONE_REMOTE = "discord"  # ‚Üê S·ª¨A: T√™n remote trong rclone config
RCLONE_FOLDER = "ZLibrary-Books"  # Folder tr√™n Google Drive
DOWNLOAD_DIR = "data/downloads/discord"  # Th∆∞ m·ª•c download t·∫°m
AUTO_DELETE_AFTER_UPLOAD = True  # T·ª± ƒë·ªông x√≥a file sau khi upload

# ===== SETUP =====
setup_logger(logging.INFO, "logs/discord_bot.log")
logger = get_logger("discord_bot")

# Discord Bot intents
intents = discord.Intents.default()
intents.message_content = True  # V·∫´n gi·ªØ cho backward compatibility

# S·ª≠ d·ª•ng commands.Bot ƒë·ªÉ h·ªó tr·ª£ c·∫£ slash commands v√† prefix commands
bot = commands.Bot(
    command_prefix='!',  # Prefix commands (legacy)
    intents=intents,
    help_command=None  # Disable default help ƒë·ªÉ d√πng custom
)


class BookDownloader:
    """
    Class x·ª≠ l√Ω download s√°ch t·ª´ Z-Library
    
    T∆∞∆°ng t·ª± logic trong test_download_single_book.py
    H·ªó tr·ª£:
    - Direct download link (/dl/)
    - Book page link (/book/)
    - T·ª± ƒë·ªông parse domain (.ec, .se, .is, ...)
    """
    
    def __init__(self):
        self.config_manager = ConfigManager("config.yaml")
        zlib_config = self.config_manager.get_zlibrary_config()
        
        self.zlibrary_service = ZLibraryService(
            email=zlib_config.get('username'),
            password=zlib_config.get('password'),
            proxy_list=zlib_config.get('proxy_list'),
            format_priority=zlib_config.get('format_priority', ['pdf', 'epub', 'mobi']),
            download_dir=DOWNLOAD_DIR
        )
        
        os.makedirs(DOWNLOAD_DIR, exist_ok=True)
        logger.info("BookDownloader initialized")
    
    def reload_credentials(self, username: str, password: str):
        """
        Reload Z-Library credentials without restarting bot
        
        Args:
            username: Z-Library email
            password: Z-Library password
        """
        try:
            # Update config file
            import yaml
            config_path = "config.yaml"
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = yaml.safe_load(f)
            
            # Update zlibrary section
            if 'zlibrary' not in config_data:
                config_data['zlibrary'] = {}
            
            config_data['zlibrary']['username'] = username
            config_data['zlibrary']['password'] = password
            
            # Write back to file
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config_data, f, default_flow_style=False, allow_unicode=True)
            
            # Reload ConfigManager
            self.config_manager = ConfigManager(config_path)
            zlib_config = self.config_manager.get_zlibrary_config()
            
            # Recreate ZLibraryService with new credentials
            self.zlibrary_service = ZLibraryService(
                email=username,
                password=password,
                proxy_list=zlib_config.get('proxy_list'),
                format_priority=zlib_config.get('format_priority', ['pdf', 'epub', 'mobi']),
                download_dir=DOWNLOAD_DIR
            )
            
            logger.info(f"Credentials reloaded for user: {username}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to reload credentials: {e}")
            return False
    
    def extract_book_info_from_url(self, url: str) -> Optional[dict]:
        """
        Tr√≠ch xu·∫•t th√¥ng tin t·ª´ URL Z-Library
        
        H·ªó tr·ª£ c√°c domain: .ec, .se, .is, .sk, ...
        Pattern: https://z-library.{domain}/book/{id}/{hash}
                 https://z-library.{domain}/dl/{id}/{hash}
        
        Supported URL formats:
        ‚úÖ /book/1269938/e536b6
        ‚úÖ /book/1269938/e536b6/filename.html
        ‚úÖ /book/1269938/e536b6?ts=1651
        ‚úÖ /book/1269938/e536b6?dsource=recommend
        ‚úÖ /book/1269938/e536b6/title.html?utm_source=google&utm_campaign=xyz
        ‚úÖ /book/1269938/e536b6#section
        ‚úÖ /dl/1269938/b88232 (direct download)
        """
        # Remove ALL query params (?xxx) and fragments (#xxx)
        # This handles: ?ts=, ?dsource=, ?utm_source=, ?ref=, etc.
        clean_url = url.split('?')[0].split('#')[0]
        
        # Pattern 1: /book/{id}/{hash}[/optional-filename.ext] (book page)
        # Regex: /book/(\d+)/([a-z0-9]+)(?:/[^/]+)?
        #   - (\d+): book ID (digits)
        #   - ([a-z0-9]+): hash (alphanumeric, case-insensitive)
        #   - (?:/[^/]+)?: optional non-capturing group for filename
        match = re.search(r'/book/(\d+)/([a-z0-9]+)(?:/[^/]+)?', clean_url, re.IGNORECASE)
        if match:
            return {
                'id': match.group(1),
                'hash': match.group(2),
                'url': url,
                'type': 'book_page',
                'domain': self._extract_domain(url)
            }
        
        # Pattern 2: /dl/{id}/{hash} (direct download)
        # Note: Some hashes may contain letters beyond a-f (not strictly hex)
        match = re.search(r'/dl/(\d+)/([a-z0-9]+)', clean_url)
        if match:
            return {
                'id': match.group(1),
                'hash': match.group(2),
                'url': url,
                'type': 'direct_download',
                'domain': self._extract_domain(url)
            }
        
        return None
    
    def _extract_domain(self, url: str) -> str:
        """Tr√≠ch xu·∫•t domain t·ª´ URL"""
        import re
        match = re.search(r'https?://([^/]+)', url)
        if match:
            return match.group(1)
        return 'z-library.ec'  # Default
    
    async def _get_download_hash_from_page(self, book_page_url: str) -> Optional[str]:
        """
        Parse book page HTML ƒë·ªÉ l·∫•y download hash th·∫≠t t·ª´ download button
        
        HTML structure:
        <a class="btn btn-default addDownloadedBook" href="/dl/1269938/f07321">
            <span>pdf</span>, 19.30 MB
        </a>
        
        Returns:
            str: Download hash (e.g., 'f07321') ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        try:
            import requests
            from bs4 import BeautifulSoup
            
            logger.info(f"Fetching book page: {book_page_url}")
            
            # Add proper headers to mimic browser
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }
            
            response = requests.get(book_page_url, headers=headers, timeout=10)
            response.raise_for_status()
            
            # Debug: Save HTML to file for inspection
            debug_html_path = "data/temp/debug_page.html"
            os.makedirs(os.path.dirname(debug_html_path), exist_ok=True)
            with open(debug_html_path, 'w', encoding='utf-8') as f:
                f.write(response.text)
            logger.info(f"Saved HTML to {debug_html_path} for debugging")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Method 1: Find by class "addDownloadedBook" (most reliable)
            # Priority: Look for primary download button (usually PDF, first format)
            download_links = soup.find_all('a', class_='addDownloadedBook')
            
            download_link = None
            if download_links:
                logger.info(f"Found {len(download_links)} download button(s)")
                # Debug: Log all found links
                for i, link in enumerate(download_links):
                    href = link.get('href')
                    format_span = link.find('span', class_='book-property__extension')
                    fmt = format_span.text.strip() if format_span else 'unknown'
                    logger.info(f"  Button {i+1}: {href} (format: {fmt})")
                
                # Take the first one (primary format)
                download_link = download_links[0]
                logger.info(f"Using first button")
            
            if not download_link:
                # Method 2: Find any <a> with href matching /dl/{id}/{hash}
                download_link = soup.find('a', href=re.compile(r'/dl/\d+/[a-z0-9]+', re.IGNORECASE))
                logger.info("Using fallback method to find download link")
            
            if download_link:
                href = download_link.get('href')
                # Try to get format from button text
                format_span = download_link.find('span', class_='book-property__extension')
                file_format = format_span.text.strip() if format_span else 'unknown'
                logger.info(f"Found download link: {href} (format: {file_format})")
                
                # Extract hash from /dl/{id}/{hash}
                match = re.search(r'/dl/\d+/([a-z0-9]+)', href, re.IGNORECASE)
                if match:
                    download_hash = match.group(1)
                    logger.info(f"Found download hash: {download_hash}")
                    return download_hash
            
            logger.warning("Could not find download link in book page")
            return None
            
        except Exception as e:
            logger.error(f"Error parsing book page: {e}")
            return None
    
    async def download_book(self, url: str) -> Optional[dict]:
        """
        Download s√°ch t·ª´ Z-Library
        
        Returns:
            dict: {
                'success': bool,
                'file_path': str,
                'file_name': str,
                'file_size': int,
                'title': str,
                'error': str (if failed)
            }
        """
        try:
            logger.info(f"B·∫Øt ƒë·∫ßu download t·ª´ URL: {url}")
            
            # Parse URL
            book_info = self.extract_book_info_from_url(url)
            if not book_info:
                return {
                    'success': False,
                    'error': 'URL kh√¥ng h·ª£p l·ªá. Vui l√≤ng cung c·∫•p URL t·ª´ Z-Library'
                }
            
            # Get book ID (works for both /book/ and /dl/ URLs)
            book_id = book_info['id']
            
            # IMPORTANT: Hash in URL expires! We must search to get fresh download_url
            # Strategy: Extract title from URL filename -> search by title -> match by ID
            logger.info(f"Book ID: {book_id}")
            
            try:
                import requests
                from bs4 import BeautifulSoup
                
                # Step 1: Fetch book page to extract ISBN
                # ISBN is unique identifier - perfect for exact search!
                book_page_url = url.split('?')[0].split('#')[0]
                if '/dl/' in book_page_url:
                    # Convert /dl/ to /book/ to access book page
                    book_page_url = book_page_url.replace('/dl/', '/book/')
                    # Remove hash part: /book/ID/hash ‚Üí /book/ID
                    parts = book_page_url.split('/')
                    if len(parts) >= 6:  # https://domain/book/ID/hash
                        book_page_url = '/'.join(parts[:5])  # Keep only up to ID
                
                logger.info(f"Fetching book page to extract ISBN: {book_page_url}")
                
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                
                try:
                    response = requests.get(book_page_url, headers=headers, timeout=10)
                    response.raise_for_status()
                except Exception as e:
                    logger.error(f"Failed to fetch book page: {e}")
                    return {
                        'success': False,
                        'error': f'‚ùå Kh√¥ng th·ªÉ truy c·∫≠p trang s√°ch: {str(e)}'
                    }
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Step 2: Extract ISBN from meta description or page content
                # Example: <meta name="description" content="...ISBN: 9780194420884...">
                isbn = None
                
                # Method 1: Check meta description
                meta_desc = soup.find('meta', attrs={'name': 'description'})
                if meta_desc and meta_desc.get('content'):
                    desc_content = meta_desc.get('content')
                    # Look for ISBN pattern: ISBN: XXXXXXXXXX or ISBN-10/13
                    isbn_match = re.search(r'ISBN[:\s-]*(\d{10,13})', desc_content, re.IGNORECASE)
                    if isbn_match:
                        isbn = isbn_match.group(1)
                        logger.info(f"Found ISBN in meta description: {isbn}")
                
                # Method 2: Look in page content for ISBN
                if not isbn:
                    # Find all text containing "ISBN"
                    isbn_elements = soup.find_all(string=re.compile(r'ISBN', re.IGNORECASE))
                    for elem in isbn_elements:
                        isbn_match = re.search(r'ISBN[:\s-]*(\d{10,13})', elem, re.IGNORECASE)
                        if isbn_match:
                            isbn = isbn_match.group(1)
                            logger.info(f"Found ISBN in page content: {isbn}")
                            break
                
                # Method 3: Look for data attributes or structured data
                if not isbn:
                    # Sometimes ISBN is in structured data (JSON-LD)
                    script_tags = soup.find_all('script', type='application/ld+json')
                    for script in script_tags:
                        try:
                            import json
                            data = json.loads(script.string)
                            if 'isbn' in data:
                                isbn = str(data['isbn'])
                                logger.info(f"Found ISBN in structured data: {isbn}")
                                break
                        except:
                            pass
                
                # Step 3: Search by ISBN (most accurate!) or fallback to get_by_id
                if not isbn:
                    logger.warning("No ISBN found in page, trying get_by_id API...")
                    
                    # Try using zlibrary's get_by_id (may fail on some domains)
                    lib = self.zlibrary_service.search_service.lib
                    
                    async def get_book_by_id():
                        try:
                            # Try to get book directly by ID
                            book = await lib.get_by_id(str(book_id))
                            return book
                        except Exception as e:
                            logger.error(f"get_by_id failed: {e}")
                            return None
                    
                    book_details = asyncio.run(get_book_by_id())
                    
                    if not book_details:
                        return {
                            'success': False,
                            'error': '‚ùå URL kh√¥ng c√≥ t√™n s√°ch v√† kh√¥ng th·ªÉ t√¨m theo ID\n\n' +
                                    'üí° Vui l√≤ng d√πng URL c√≥ t√™n s√°ch, v√≠ d·ª•:\n' +
                                    '‚úÖ https://z-library.xx/book/123/abc/book-title.html\n' +
                                    '‚ùå https://z-library.xx/book/123/abc'
                        }
                    
                    # Got book details directly, extract info
                    download_url = book_details.get('download_url')
                    if not download_url:
                        return {
                            'success': False,
                            'error': '‚ùå S√°ch kh√¥ng c√≥ link download'
                        }
                    
                    title = book_details.get('name', f'Book_{book_id}')
                    authors = book_details.get('authors', 'Unknown')
                    extension = book_details.get('extension', 'pdf')
                    
                    logger.info(f"Got book via get_by_id: {title}")
                    
                    # Skip search, go directly to download
                    book_data = {
                        'zlibrary_id': book_id,
                        'title': title,
                        'authors': authors,
                        'download_url': download_url,
                        'extension': extension,
                        'url': url
                    }
                    
                    logger.info(f"Downloading book ID: {book_id} (using zlibrary service authenticated session)")
                    file_path = self.zlibrary_service.download_book(book_data, DOWNLOAD_DIR)
                    
                    if not file_path or not os.path.exists(file_path):
                        return {
                            'success': False,
                            'error': 'Download th·∫•t b·∫°i. File kh√¥ng t·ªìn t·∫°i sau khi download.'
                        }
                    
                    # Continue to upload...
                    file_size = os.path.getsize(file_path)
                    file_name = os.path.basename(file_path)
                    
                    logger.info(f"Download th√†nh c√¥ng: {file_name} ({file_size} bytes)")
                    
                    # Upload to Google Drive
                    logger.info(f"Uploading {file_name} l√™n {RCLONE_REMOTE}:{RCLONE_FOLDER}/{file_name}")
                    uploader = RcloneUploader(RCLONE_REMOTE, RCLONE_FOLDER)
                    
                    upload_result = uploader.upload_file(file_path)
                    if not upload_result['success']:
                        return {
                            'success': False,
                            'error': f"Upload th·∫•t b·∫°i: {upload_result.get('error', 'Unknown error')}"
                        }
                    
                    logger.info(f"Upload th√†nh c√¥ng: {upload_result['remote_path']}")
                    
                    # Get public link
                    link_result = uploader.get_public_link(file_name)
                    public_link = link_result.get('link', 'Kh√¥ng th·ªÉ t·∫°o public link')
                    
                    logger.info(f"Public link created: {public_link}")
                    
                    # Cleanup
                    if AUTO_DELETE_AFTER_UPLOAD:
                        try:
                            os.remove(file_path)
                            logger.info(f"ƒê√£ x√≥a file local: {file_path}")
                        except Exception as e:
                            logger.warning(f"Kh√¥ng th·ªÉ x√≥a file: {e}")
                    
                    logger.info(f"Ho√†n th√†nh download qua get_by_id: {file_name}")
                    
                    return {
                        'success': True,
                        'file_name': file_name,
                        'file_size': file_size,
                        'public_link': public_link,
                        'remote_path': upload_result['remote_path']
                    }
                
                # Step 4: Search by ISBN on Z-Library website (crawl search results)
                # ISBN search on web: https://z-library.ec/s/9780194420884
                search_url = f"https://z-library.ec/s/{isbn}"
                logger.info(f"Searching Z-Library web for ISBN: {search_url}")
                
                try:
                    search_response = requests.get(search_url, headers=headers, timeout=10)
                    search_response.raise_for_status()
                    
                    # Save search HTML for debugging
                    debug_search_html = "data/temp/debug_search.html"
                    os.makedirs(os.path.dirname(debug_search_html), exist_ok=True)
                    with open(debug_search_html, 'w', encoding='utf-8') as f:
                        f.write(search_response.text)
                    logger.info(f"Saved search HTML to {debug_search_html}")
                    
                    search_soup = BeautifulSoup(search_response.content, 'html.parser')
                    
                    # Z-Library uses custom web components: <z-bookcard>
                    # Extract book info from z-bookcard attributes
                    bookcards = search_soup.find_all('z-bookcard')
                    logger.info(f"Found {len(bookcards)} z-bookcard element(s)")
                    
                    book_links = []
                    for card in bookcards:
                        # z-bookcard has these important attributes:
                        # - id="11948830" (book ID)
                        # - isbn="9780194420884"  
                        # - href="/book/11948830/2c2f55/oxford-english-grammar-course-basic.html"
                        # - extension="pdf"
                        # - title in <div slot="title">
                        # - author in <div slot="author">
                        
                        card_id = card.get('id')
                        card_isbn = card.get('isbn')
                        card_href = card.get('href')
                        card_ext = card.get('extension', '').lower()
                        
                        # Get title from slot
                        title_slot = card.find('div', attrs={'slot': 'title'})
                        card_title = title_slot.get_text(strip=True) if title_slot else ''
                        
                        # Get author from slot
                        author_slot = card.find('div', attrs={'slot': 'author'})
                        card_author = author_slot.get_text(strip=True) if author_slot else ''
                        
                        logger.info(f"  Card: ID={card_id}, ISBN={card_isbn}, Format={card_ext}, Title='{card_title[:50]}'")
                        
                        # Create a fake link object with extracted data
                        class BookLink:
                            def __init__(self, card_data):
                                self.data = card_data
                            
                            def get(self, attr, default=''):
                                if attr == 'href':
                                    return self.data.get('href', '')
                                return default
                            
                            @property
                            def parent(self):
                                # Return self so ISBN check works
                                return self
                            
                            def get_text(self, strip=False):
                                # Return ISBN so parent.get_text() works
                                return self.data.get('isbn', '')
                        
                        book_links.append(BookLink({
                            'id': card_id,
                            'href': card_href,
                            'isbn': card_isbn,
                            'extension': card_ext,
                            'title': card_title,
                            'author': card_author
                        }))
                    
                    if not book_links:
                        logger.error(f"No books found for ISBN {isbn} on web search")
                        logger.error(f"HTML preview: {search_response.text[:500]}")
                        return {
                            'success': False,
                            'error': f'‚ùå Kh√¥ng t√¨m th·∫•y s√°ch v·ªõi ISBN: {isbn}\nüí° Check log file: {debug_search_html}'
                        }
                    
                    logger.info(f"Found {len(book_links)} potential book(s) in search results")
                    
                    # Step 4.5: VALIDATE and CHOOSE the best match
                    # Don't just take the first one - verify it's the right book!
                    from difflib import SequenceMatcher
                    
                    def similarity(a, b):
                        """Calculate text similarity (0-1)"""
                        return SequenceMatcher(None, a.lower(), b.lower()).ratio()
                    
                    best_match = None
                    best_score = 0
                    
                    # Get format priority from config
                    zlib_config = self.config_manager.get_zlibrary_config()
                    format_priority = zlib_config.get('format_priority', ['pdf', 'epub', 'mobi', 'azw3'])
                    
                    for i, link in enumerate(book_links[:10]):  # Check first 10 results
                        # Extract data from BookLink object
                        if hasattr(link, 'data'):
                            # Custom BookLink from z-bookcard
                            candidate_id = link.data.get('id')
                            candidate_title = link.data.get('title', '')
                            candidate_format = link.data.get('extension', 'unknown')
                            candidate_isbn = link.data.get('isbn', '')
                            href = link.data.get('href', '')
                        else:
                            # Fallback for regular <a> tags (if any)
                            href = link.get('href', '')
                            
                            # Extract book ID
                            id_match = re.search(r'/?book/(\d+)', href)
                            if not id_match:
                                continue
                            
                            candidate_id = id_match.group(1)
                            
                            # Get book title from link text or parent element
                            title_elem = link.find('h3') or link.find(attrs={'itemprop': 'name'}) or link
                            candidate_title = title_elem.get_text(strip=True) if title_elem else ''
                            
                            # Try to get format from nearby elements
                            parent = link.parent
                            format_elem = parent.find(class_=re.compile(r'extension|format', re.IGNORECASE)) if parent else None
                            candidate_format = format_elem.get_text(strip=True).lower() if format_elem else 'unknown'
                            candidate_isbn = ''
                        
                        if not candidate_id:
                            continue
                        
                        # Calculate match score
                        score = 0
                        
                        # 1. ISBN match = +50 points (most important!)
                        if candidate_isbn and candidate_isbn == isbn:
                            score += 50
                            logger.info(f"  Result {i+1}: ISBN exact match! +50")
                        
                        # 2. Format priority = +30 points for PDF, +20 for epub, etc.
                        for priority_idx, fmt in enumerate(format_priority):
                            if fmt in candidate_format:
                                score += (30 - priority_idx * 5)
                                logger.info(f"  Result {i+1}: Format {fmt} = +{30 - priority_idx * 5}")
                                break
                        
                        # 3. Title similarity (if we extracted title from URL) = up to +20 points
                        if book_info.get('title'):
                            title_sim = similarity(book_info['title'], candidate_title)
                            title_score = int(title_sim * 20)
                            score += title_score
                            if title_score > 0:
                                logger.info(f"  Result {i+1}: Title similarity {title_sim:.2f} = +{title_score}")
                        
                        logger.info(f"  Result {i+1}: ID={candidate_id}, Title='{candidate_title[:50]}', Format={candidate_format}, Score={score}")
                        
                        if score > best_score:
                            best_score = score
                            best_match = {
                                'id': candidate_id,
                                'title': candidate_title,
                                'format': candidate_format,
                                'link': link
                            }
                    
                    if not best_match:
                        logger.error("No valid book ID found in search results")
                        return {
                            'success': False,
                            'error': '‚ùå Kh√¥ng th·ªÉ parse k·∫øt qu·∫£ search'
                        }
                    
                    found_book_id = best_match['id']
                    logger.info(f"‚úÖ BEST MATCH: ID={found_book_id}, Title='{best_match['title'][:50]}', Format={best_match['format']}, Score={best_score}")
                    
                except Exception as e:
                    logger.error(f"Error searching web for ISBN: {e}")
                    return {
                        'success': False,
                        'error': f'‚ùå L·ªói khi search ISBN: {str(e)}'
                    }
                
                # Step 5: Use get_by_id with the found book ID
                lib = self.zlibrary_service.search_service.lib
                logger.info(f"Getting book details via get_by_id({found_book_id})...")
                
                async def get_book_by_id():
                    try:
                        book = await lib.get_by_id(str(found_book_id))
                        return book
                    except Exception as e:
                        logger.error(f"get_by_id failed: {e}")
                        return None
                
                book_details = asyncio.run(get_book_by_id())
                
                if not book_details:
                    return {
                        'success': False,
                        'error': f'‚ùå Kh√¥ng th·ªÉ l·∫•y th√¥ng tin s√°ch (ID: {found_book_id})'
                    }
                
                download_url = book_details.get('download_url')
                if not download_url:
                    return {
                        'success': False,
                        'error': '‚ùå S√°ch kh√¥ng c√≥ link download'
                    }
                
                title = book_details.get('name', f'Book_{found_book_id}')
                authors = book_details.get('authors', 'Unknown')
                extension = book_details.get('extension', 'pdf')
                
                logger.info(f"Got book: {title}")
                logger.info(f"Got fresh download_url: {download_url}")
                
                logger.info(f"Got fresh download_url: {download_url}")
                
            except Exception as e:
                logger.error(f"Error getting fresh download URL: {e}")
                import traceback
                traceback.print_exc()
                return {
                    'success': False,
                    'error': f'‚ùå L·ªói: {str(e)}'
                }
            
            # Chu·∫©n b·ªã book_info cho service
            book_data = {
                'zlibrary_id': book_id,
                'title': title,
                'authors': authors,
                'download_url': download_url,
                'extension': extension,
                'url': url
            }
            logger.info(f"Downloading book ID: {book_info['id']} (using zlibrary service authenticated session)")
            file_path = self.zlibrary_service.download_book(book_data, DOWNLOAD_DIR)
            
            if not file_path or not os.path.exists(file_path):
                return {
                    'success': False,
                    'error': 'Download th·∫•t b·∫°i. File kh√¥ng t·ªìn t·∫°i sau khi download.'
                }
            
            # L·∫•y th√¥ng tin file
            file_size = os.path.getsize(file_path)
            file_name = os.path.basename(file_path)
            
            logger.info(f"Download th√†nh c√¥ng: {file_name} ({file_size} bytes)")
            
            return {
                'success': True,
                'file_path': file_path,
                'file_name': file_name,
                'file_size': file_size,
                'title': title
            }
            
        except Exception as e:
            logger.error(f"L·ªói khi download: {str(e)}")
            return {
                'success': False,
                'error': f'L·ªói: {str(e)}'
            }


class RcloneUploader:
    """Class x·ª≠ l√Ω upload l√™n Google Drive b·∫±ng Rclone"""
    
    def __init__(self, remote: str, folder: str):
        self.remote = remote
        self.folder = folder
        logger.info(f"RcloneUploader initialized: {remote}:{folder}")
    
    def check_rclone_installed(self) -> bool:
        """Ki·ªÉm tra xem rclone ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ch∆∞a"""
        try:
            result = subprocess.run(['rclone', 'version'], 
                                   capture_output=True, 
                                   text=True, 
                                   timeout=5)
            return result.returncode == 0
        except Exception as e:
            logger.error(f"Rclone kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t: {e}")
            return False
    
    async def upload_file(self, file_path: str) -> Optional[dict]:
        """
        Upload file l√™n Google Drive
        
        Returns:
            dict: {
                'success': bool,
                'remote_path': str,
                'share_link': str (if available),
                'error': str (if failed)
            }
        """
        try:
            if not self.check_rclone_installed():
                return {
                    'success': False,
                    'error': 'Rclone ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t tr√™n VPS'
                }
            
            file_name = os.path.basename(file_path)
            remote_path = f"{self.remote}:{self.folder}/{file_name}"
            
            logger.info(f"Uploading {file_name} l√™n {remote_path}")
            
            # Upload v·ªõi progress
            cmd = [
                'rclone', 'copy',
                file_path,
                f"{self.remote}:{self.folder}",
                '--progress',
                '--stats', '1s'
            ]
            
            # Ch·∫°y rclone
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode != 0:
                error_msg = stderr.decode('utf-8')
                logger.error(f"Upload th·∫•t b·∫°i: {error_msg}")
                return {
                    'success': False,
                    'error': f'Rclone error: {error_msg}'
                }
            
            logger.info(f"Upload th√†nh c√¥ng: {remote_path}")
            
            # T·∫°o public link (n·∫øu c√≥ th·ªÉ)
            share_link = await self.create_public_link(file_name)
            
            return {
                'success': True,
                'remote_path': remote_path,
                'file_name': file_name,
                'share_link': share_link
            }
            
        except Exception as e:
            logger.error(f"L·ªói khi upload: {str(e)}")
            return {
                'success': False,
                'error': f'L·ªói: {str(e)}'
            }
    
    async def create_public_link(self, file_name: str) -> Optional[str]:
        """
        T·∫°o public link cho file (n·∫øu Google Drive h·ªó tr·ª£)
        
        Note: C·∫ßn c·∫•u h√¨nh rclone v·ªõi Google Drive API
        """
        try:
            # L·∫•y link t·ª´ rclone link
            cmd = [
                'rclone', 'link',
                f"{self.remote}:{self.folder}/{file_name}"
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                link = stdout.decode('utf-8').strip()
                logger.info(f"Public link created: {link}")
                return link
            else:
                logger.warning("Kh√¥ng th·ªÉ t·∫°o public link, c√≥ th·ªÉ c·∫ßn c·∫•u h√¨nh th√™m")
                return None
                
        except Exception as e:
            logger.warning(f"Kh√¥ng th·ªÉ t·∫°o public link: {e}")
            return None


# ===== DISCORD BOT COMMANDS =====

downloader = BookDownloader()
uploader = RcloneUploader(RCLONE_REMOTE, RCLONE_FOLDER)


@bot.event
async def on_ready():
    logger.info(f'Bot ƒë√£ ƒëƒÉng nh·∫≠p: {bot.user.name}')
    print(f'‚úÖ Bot ƒë√£ s·∫µn s√†ng: {bot.user.name}')
    print(f'üìö Slash commands: /download, /quota, /ping, /help')
    print(f'üìö Prefix commands: !download, !quota, !ping, !help_bot')
    
    # Sync slash commands v·ªõi Discord
    try:
        synced = await bot.tree.sync()
        logger.info(f"ƒê√£ sync {len(synced)} slash command(s)")
        print(f"‚úÖ ƒê√£ sync {len(synced)} slash command(s)")
    except Exception as e:
        logger.error(f"L·ªói khi sync commands: {e}")
        print(f"‚ö†Ô∏è  L·ªói sync commands: {e}")


# ===== HELPER FUNCTION =====

async def process_download_request(interaction_or_ctx, url: str, is_slash: bool = False):
    """
    Helper function x·ª≠ l√Ω download request
    D√πng chung cho c·∫£ slash command v√† prefix command
    
    Args:
        interaction_or_ctx: discord.Interaction (slash) ho·∫∑c commands.Context (prefix)
        url: Z-Library URL
        is_slash: True n·∫øu l√† slash command, False n·∫øu l√† prefix command
    """
    # Get author info and initialize status_msg
    status_msg = None
    if is_slash:
        author = interaction_or_ctx.user
        # Defer ƒë·ªÉ c√≥ th·ªùi gian x·ª≠ l√Ω (15 ph√∫t thay v√¨ 3 gi√¢y)
        await interaction_or_ctx.response.defer()
    else:
        author = interaction_or_ctx.author
        status_msg = await interaction_or_ctx.send(f"‚è≥ ƒêang x·ª≠ l√Ω request c·ªßa {author.mention}...")
    
    try:
        # B∆∞·ªõc 1: Download
        if is_slash:
            await interaction_or_ctx.followup.send(f"üì• **[1/4]** ƒêang download s√°ch t·ª´ Z-Library...\n‚è≥ Request t·ª´ {author.mention}")
        else:
            await status_msg.edit(content="üì• **[1/4]** ƒêang download s√°ch t·ª´ Z-Library...")
        
        logger.info(f"User {author} y√™u c·∫ßu download: {url}")
        
        download_result = await downloader.download_book(url)
        
        if not download_result['success']:
            error_msg = f"‚ùå **Download th·∫•t b·∫°i:**\n```{download_result['error']}```"
            if is_slash:
                await interaction_or_ctx.followup.send(error_msg)
            else:
                await status_msg.edit(content=error_msg)
            return
        
        file_path = download_result['file_path']
        file_name = download_result['file_name']
        file_size_mb = download_result['file_size'] / (1024 * 1024)
        
        # B∆∞·ªõc 2: Upload l√™n Google Drive
        upload_msg = f"‚òÅÔ∏è **[2/4]** ƒêang upload `{file_name}` ({file_size_mb:.2f} MB) l√™n Google Drive..."
        if is_slash:
            await interaction_or_ctx.followup.send(upload_msg)
        else:
            await status_msg.edit(content=upload_msg)
        
        upload_result = await uploader.upload_file(file_path)
        
        if not upload_result['success']:
            error_msg = f"‚ùå **Upload th·∫•t b·∫°i:**\n```{upload_result['error']}```"
            if is_slash:
                await interaction_or_ctx.followup.send(error_msg)
            else:
                await status_msg.edit(content=error_msg)
            return
        
        # B∆∞·ªõc 3: T·∫°o message k·∫øt qu·∫£
        if is_slash:
            await interaction_or_ctx.followup.send("üìã **[3/4]** ƒêang t·∫°o th√¥ng tin chia s·∫ª...")
        else:
            await status_msg.edit(content="üìã **[3/4]** ƒêang t·∫°o th√¥ng tin chia s·∫ª...")
        
        embed = discord.Embed(
            title="‚úÖ Download & Upload Th√†nh C√¥ng!",
            color=discord.Color.green(),
            description=f"S√°ch ƒë√£ ƒë∆∞·ª£c t·∫£i v√† upload l√™n Google Drive"
        )
        
        embed.add_field(name="üìñ File Name", value=f"`{file_name}`", inline=False)
        embed.add_field(name="üìä File Size", value=f"{file_size_mb:.2f} MB", inline=True)
        embed.add_field(name="‚òÅÔ∏è Remote Path", value=f"`{upload_result['remote_path']}`", inline=False)
        
        if upload_result.get('share_link'):
            embed.add_field(name="üîó Public Link", value=upload_result['share_link'], inline=False)
        else:
            embed.add_field(
                name="üìÅ Access", 
                value=f"File ƒë√£ ƒë∆∞·ª£c upload v√†o folder `{RCLONE_FOLDER}` tr√™n Google Drive\n"
                      f"D√πng l·ªánh `rclone link {RCLONE_REMOTE}:{RCLONE_FOLDER}/{file_name}` ƒë·ªÉ l·∫•y link",
                inline=False
            )
        
        embed.set_footer(text=f"Requested by {author.name}", icon_url=author.avatar.url if author.avatar else None)
        
        if is_slash:
            await interaction_or_ctx.followup.send(embed=embed)
        else:
            await status_msg.edit(content=None, embed=embed)
        
        # B∆∞·ªõc 4: Cleanup (x√≥a file local n·∫øu ƒë∆∞·ª£c b·∫≠t)
        if AUTO_DELETE_AFTER_UPLOAD:
            await asyncio.sleep(2)
            try:
                os.remove(file_path)
                logger.info(f"ƒê√£ x√≥a file local: {file_path}")
                cleanup_msg = f"üóëÔ∏è **[4/4]** ƒê√£ x√≥a file t·∫°m tr√™n VPS"
                if is_slash:
                    await interaction_or_ctx.followup.send(cleanup_msg)
                else:
                    await interaction_or_ctx.send(cleanup_msg)
            except Exception as e:
                logger.warning(f"Kh√¥ng th·ªÉ x√≥a file: {e}")
        
        logger.info(f"Ho√†n th√†nh request cho user {author}: {file_name}")
        
    except Exception as e:
        logger.error(f"L·ªói khi x·ª≠ l√Ω command: {e}")
        error_msg = f"‚ùå **L·ªói kh√¥ng mong mu·ªën:**\n```{str(e)}```"
        if is_slash:
            await interaction_or_ctx.followup.send(error_msg)
        else:
            await status_msg.edit(content=error_msg)


# ===== SLASH COMMANDS =====

@bot.tree.command(name="download", description="üì• Download s√°ch t·ª´ Z-Library v√† upload l√™n Google Drive")
async def slash_download(interaction: discord.Interaction, url: str):
    """
    Slash command: /download <url>
    
    Parameters:
        url: URL c·ªßa s√°ch tr√™n Z-Library (.ec, .se, .is, .sk)
    """
    await process_download_request(interaction, url, is_slash=True)


@bot.tree.command(name="quota", description="üìä Ki·ªÉm tra quota Z-Library c√≤n l·∫°i")
async def slash_quota(interaction: discord.Interaction):
    """Slash command: /quota"""
    await interaction.response.defer()
    
    try:
        limits = downloader.zlibrary_service.get_download_limits()
        
        embed = discord.Embed(
            title="üìä Z-Library Download Quota",
            color=discord.Color.blue()
        )
        
        embed.add_field(name="Daily Limit", value=limits.get('daily_amount', 'N/A'), inline=True)
        embed.add_field(name="Remaining", value=limits.get('daily_remaining', 'N/A'), inline=True)
        embed.add_field(name="Next Reset", value=limits.get('daily_reset', 'N/A'), inline=False)
        
        await interaction.followup.send(embed=embed)
        
    except Exception as e:
        await interaction.followup.send(f"‚ùå Kh√¥ng th·ªÉ l·∫•y th√¥ng tin quota: {str(e)}")


@bot.tree.command(name="set_credentials", description="üîë Thay ƒë·ªïi Z-Library credentials (khi h·∫øt quota)")
async def slash_set_credentials(interaction: discord.Interaction, email: str, password: str):
    """
    Slash command: /set_credentials <email> <password>
    
    Thay ƒë·ªïi Z-Library account credentials
    H·ªØu √≠ch khi account hi·ªán t·∫°i h·∫øt quota
    
    Parameters:
        email: Z-Library email/username
        password: Z-Library password
    """
    # Check if user has permission (optional - c√≥ th·ªÉ th√™m role check)
    # if not interaction.user.guild_permissions.administrator:
    #     await interaction.response.send_message("‚ùå Ch·ªâ admin m·ªõi c√≥ th·ªÉ thay ƒë·ªïi credentials!", ephemeral=True)
    #     return
    
    await interaction.response.defer(ephemeral=True)  # Response ri√™ng t∆∞ (ch·ªâ user th·∫•y)
    
    try:
        # Reload credentials
        success = downloader.reload_credentials(email, password)
        
        if success:
            # Get new quota info
            try:
                limits = downloader.zlibrary_service.get_download_limits()
                quota_info = (
                    f"\n\nüìä **New Account Quota:**\n"
                    f"‚Ä¢ Daily Limit: {limits.get('daily_amount', 'N/A')}\n"
                    f"‚Ä¢ Remaining: {limits.get('daily_remaining', 'N/A')}\n"
                    f"‚Ä¢ Next Reset: {limits.get('daily_reset', 'N/A')}"
                )
            except:
                quota_info = ""
            
            await interaction.followup.send(
                f"‚úÖ **Credentials Updated Successfully!**\n"
                f"üìß New account: `{email}`\n"
                f"üîê Password: `{'*' * len(password)}`"
                f"{quota_info}",
                ephemeral=True
            )
            
            logger.info(f"Credentials changed by {interaction.user.name} to {email}")
            
        else:
            await interaction.followup.send(
                f"‚ùå **Failed to update credentials!**\n"
                f"Check logs for details.",
                ephemeral=True
            )
    
    except Exception as e:
        logger.error(f"Error changing credentials: {e}")
        await interaction.followup.send(
            f"‚ùå **Error:**\n```{str(e)}```",
            ephemeral=True
        )


@bot.tree.command(name="version", description="üì¶ Ki·ªÉm tra version code bot")
async def slash_version(interaction: discord.Interaction):
    """Slash command: /version - Check bot version"""
    try:
        import subprocess
        # Get git commit hash
        commit = subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD']).decode('ascii').strip()
        # Get git commit date
        commit_date = subprocess.check_output(['git', 'log', '-1', '--format=%cd', '--date=short']).decode('ascii').strip()
        
        embed = discord.Embed(
            title="üì¶ Bot Version Info",
            color=discord.Color.blue()
        )
        embed.add_field(name="Git Commit", value=f"`{commit}`", inline=True)
        embed.add_field(name="Commit Date", value=commit_date, inline=True)
        embed.add_field(name="Status", value="‚úÖ Running with HTML parsing fix", inline=False)
        
        await interaction.response.send_message(embed=embed)
    except Exception as e:
        await interaction.response.send_message(f"‚ö†Ô∏è Cannot get version: {str(e)}")


@bot.tree.command(name="ping", description="üèì Ki·ªÉm tra bot c√≥ ho·∫°t ƒë·ªông kh√¥ng")
async def slash_ping(interaction: discord.Interaction):
    """Slash command: /ping"""
    latency_ms = round(bot.latency * 1000)
    await interaction.response.send_message(f'üèì Pong! Latency: {latency_ms}ms')


@bot.tree.command(name="help", description="üìö Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng bot")
async def slash_help(interaction: discord.Interaction):
    """Slash command: /help"""
    embed = discord.Embed(
        title="üìö Z-Library Discord Bot - H∆∞·ªõng D·∫´n",
        description="Bot t·ª± ƒë·ªông download s√°ch t·ª´ Z-Library v√† upload l√™n Google Drive",
        color=discord.Color.purple()
    )
    
    embed.add_field(
        name="‚ö° Slash Commands (Modern)",
        value=(
            "`/download <url>` - Download v√† upload s√°ch\n"
            "`/quota` - Ki·ªÉm tra quota c√≤n l·∫°i\n"
            "`/set_credentials <email> <password>` - ƒê·ªïi Z-Library account\n"
            "`/ping` - Test bot\n"
            "`/help` - Xem h∆∞·ªõng d·∫´n n√†y"
        ),
        inline=False
    )
    
    embed.add_field(
        name="üìù Prefix Commands (Legacy)",
        value=(
            "`!download <url>` - Download v√† upload s√°ch\n"
            "`!quota` - Ki·ªÉm tra quota\n"
            "`!ping` - Test bot\n"
            "`!help_bot` - Xem h∆∞·ªõng d·∫´n"
        ),
        inline=False
    )
    
    embed.add_field(
        name="üîó Supported URL Types",
        value=(
            "Bot t·ª± ƒë·ªông t√¨m v√† download v·ªõi URL m·ªõi nh·∫•t!\n\n"
            "‚úÖ **Book page:** `https://z-library.xx/book/123456/abc123`\n"
            "‚úÖ **Direct link:** `https://z-library.xx/dl/123456/abc123`\n\n"
            "üí° **Tip:** Copy b·∫•t k·ª≥ link n√†o t·ª´ Z-Library ƒë·ªÅu ƒë∆∞·ª£c!"
        ),
        inline=False
    )
    
    embed.set_footer(text="Powered by Z-Library + Rclone")
    
    await interaction.response.send_message(embed=embed)


# ===== PREFIX COMMANDS (Backward Compatible) =====

@bot.command(name='download', help='Download s√°ch t·ª´ Z-Library v√† upload l√™n Google Drive')
async def download_command(ctx, url: str = None):
    """
    Prefix command: !download <z-library-url>
    """
    if not url:
        await ctx.send(
            "‚ùå Vui l√≤ng cung c·∫•p URL Z-Library!\n"
            "**V√≠ d·ª•:**\n"
            "‚Ä¢ `!download https://z-library.ec/book/12345/abcdef`\n"
            "‚Ä¢ `!download https://z-library.ec/dl/12345/abcdef` (direct link)\n\n"
            "üí° **Tip:** D√πng slash command `/download` cho tr·∫£i nghi·ªám t·ªët h∆°n!"
        )
        return
    
    await process_download_request(ctx, url, is_slash=False)


@bot.command(name='ping', help='Ki·ªÉm tra bot c√≥ ho·∫°t ƒë·ªông kh√¥ng')
async def ping_command(ctx):
    """Prefix command: !ping"""
    latency_ms = round(bot.latency * 1000)
    await ctx.send(
        f'üèì Pong! Latency: {latency_ms}ms\n'
        f'üí° **Tip:** D√πng `/ping` cho tr·∫£i nghi·ªám t·ªët h∆°n!'
    )


@bot.command(name='quota', help='Ki·ªÉm tra quota Z-Library c√≤n l·∫°i')
async def quota_command(ctx):
    """Prefix command: !quota"""
    try:
        limits = downloader.zlibrary_service.get_download_limits()
        
        embed = discord.Embed(
            title="üìä Z-Library Download Quota",
            color=discord.Color.blue()
        )
        
        embed.add_field(name="Daily Limit", value=limits.get('daily_amount', 'N/A'), inline=True)
        embed.add_field(name="Remaining", value=limits.get('daily_remaining', 'N/A'), inline=True)
        embed.add_field(name="Next Reset", value=limits.get('daily_reset', 'N/A'), inline=False)
        
        embed.set_footer(text="üí° Tip: D√πng /quota cho tr·∫£i nghi·ªám t·ªët h∆°n!")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"‚ùå Kh√¥ng th·ªÉ l·∫•y th√¥ng tin quota: {str(e)}")


@bot.command(name='help_bot', help='Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng')
async def help_bot_command(ctx):
    """Prefix command: !help_bot (redirects to /help)"""
    await ctx.send(
        "ÔøΩ **Bot ƒë√£ chuy·ªÉn sang d√πng Slash Commands!**\n"
        "G√µ `/help` ƒë·ªÉ xem h∆∞·ªõng d·∫´n ƒë·∫ßy ƒë·ªß\n\n"
        "**Quick commands:**\n"
        "‚Ä¢ `/download <url>` - Download s√°ch\n"
        "‚Ä¢ `/quota` - Check quota\n"
        "‚Ä¢ `/ping` - Test bot\n"
        "‚Ä¢ `/help` - Xem h∆∞·ªõng d·∫´n chi ti·∫øt"
    )


# ===== MAIN =====

def main():
    """Kh·ªüi ƒë·ªông Discord Bot"""
    
    if DISCORD_TOKEN == "YOUR_DISCORD_BOT_TOKEN":
        print("‚ùå L·ªói: Ch∆∞a c·∫•u h√¨nh DISCORD_TOKEN")
        print("Vui l√≤ng s·ª≠a DISCORD_TOKEN trong file discord_bot.py")
        return
    
    print("=" * 80)
    print("ü§ñ DISCORD BOT - Z-LIBRARY DOWNLOADER")
    print("=" * 80)
    print()
    print("‚úÖ ƒêang kh·ªüi ƒë·ªông bot...")
    print(f"üìÅ Download directory: {DOWNLOAD_DIR}")
    print(f"‚òÅÔ∏è  Rclone remote: {RCLONE_REMOTE}:{RCLONE_FOLDER}")
    print(f"üóëÔ∏è  Auto delete: {AUTO_DELETE_AFTER_UPLOAD}")
    print()
    
    try:
        bot.run(DISCORD_TOKEN)
    except Exception as e:
        logger.error(f"L·ªói khi ch·∫°y bot: {e}")
        print(f"‚ùå L·ªói: {e}")


if __name__ == "__main__":
    main()
